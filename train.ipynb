{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8856e775-abe2-4ff0-bdc8-3c339db78e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (6.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494dfdbc-61a9-4b22-891f-1301f96ef8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (4.52.4)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from transformers) (0.32.3)\n",
      "Requirement already satisfied: numpy>=1.17 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.11-cp310-cp310-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.6.2-cp310-cp310-win_amd64.whl.metadata (17 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.4.4-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.3.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.20.0-cp310-cp310-win_amd64.whl.metadata (74 kB)\n",
      "Requirement already satisfied: idna>=2.0 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: colorama in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in f:\\users\\djamel\\appdata\\local\\anaconda3\\envs\\module_7\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading aiohttp-3.12.11-cp310-cp310-win_amd64.whl (449 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached multidict-6.4.4-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Using cached yarl-1.20.0-cp310-cp310-win_amd64.whl (92 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.6.2-cp310-cp310-win_amd64.whl (45 kB)\n",
      "Using cached propcache-0.3.1-cp310-cp310-win_amd64.whl (45 kB)\n",
      "Using cached xxhash-3.5.0-cp310-cp310-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, propcache, multidict, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "\n",
      "   --- ------------------------------------  1/13 [propcache]\n",
      "  Attempting uninstall: fsspec\n",
      "   --- ------------------------------------  1/13 [propcache]\n",
      "    Found existing installation: fsspec 2025.5.1\n",
      "   --- ------------------------------------  1/13 [propcache]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "    Uninstalling fsspec-2025.5.1:\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "      Successfully uninstalled fsspec-2025.5.1\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   ------------------ ---------------------  6/13 [async-timeout]\n",
      "   ------------------------ ---------------  8/13 [yarl]\n",
      "   ------------------------ ---------------  8/13 [yarl]\n",
      "   --------------------------- ------------  9/13 [multiprocess]\n",
      "   --------------------------- ------------  9/13 [multiprocess]\n",
      "   --------------------------- ------------  9/13 [multiprocess]\n",
      "   --------------------------- ------------  9/13 [multiprocess]\n",
      "   --------------------------- ------------  9/13 [multiprocess]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ---------------------------------------- 13/13 [datasets]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.11 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.6.0 dill-0.3.8 frozenlist-1.6.2 fsspec-2025.3.0 multidict-6.4.4 multiprocess-0.70.16 propcache-0.3.1 xxhash-3.5.0 yarl-1.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f2d2b76-57aa-4f9a-8830-050ce1b872ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 18:24:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RandomForest terminé avec précision=0.71 | F1=0.73 | AUC=0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 18:24:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LogisticRegression terminé avec précision=0.71 | F1=0.70 | AUC=0.77\n",
      "[LightGBM] [Info] Number of positive: 6405, number of negative: 6395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31004\n",
      "[LightGBM] [Info] Number of data points in the train set: 12800, number of used features: 817\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500391 -> initscore=0.001563\n",
      "[LightGBM] [Info] Start training from score 0.001563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "F:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "F:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025/06/09 18:25:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LightGBM terminé avec précision=0.73 | F1=0.74 | AUC=0.81\n",
      "🔄 Embedding avec Universal Sentence Encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "2025/06/09 18:26:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ USE + MLP terminé avec accuracy=0.75 | F1=0.75 | AUC=0.83\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 91s 214ms/step - loss: 0.5820 - accuracy: 0.6856 - val_loss: 0.5206 - val_accuracy: 0.7494\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 88s 221ms/step - loss: 0.3589 - accuracy: 0.8440 - val_loss: 0.5618 - val_accuracy: 0.7469\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 89s 222ms/step - loss: 0.1982 - accuracy: 0.9223 - val_loss: 0.6794 - val_accuracy: 0.7300\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 94s 236ms/step - loss: 0.1178 - accuracy: 0.9564 - val_loss: 0.9277 - val_accuracy: 0.7056\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 91s 227ms/step - loss: 0.0779 - accuracy: 0.9723 - val_loss: 0.9531 - val_accuracy: 0.7163\n",
      "100/100 [==============================] - 9s 65ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 18:34:04 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Djamel\\AppData\\Local\\Temp\\tmp6uzo45up\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Djamel\\AppData\\Local\\Temp\\tmp6uzo45up\\model\\data\\model\\assets\n",
      "2025/06/09 18:34:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bidirectional LSTM terminé avec acc=0.72 | f1=0.71 | auc=0.79\n",
      "📦 Modèle BERT\n",
      "📥 Chargement des données BERT...\n",
      "🧠 Initialisation du modèle BERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Entraînement en cours...\n",
      " 61/800 [=>............................] - ETA: 6:34:20 - loss: 0.7276 - accuracy: 0.4785 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# === Entraînement BERT ===\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📦 Modèle BERT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 84\u001b[0m \u001b[43mbuild_and_train_bert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Formation\\module_7\\mlflow_project\\models\\bert_model.py:47\u001b[0m, in \u001b[0;36mbuild_and_train_bert\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_params({\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_name,\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_len\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_len,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: learning_rate\n\u001b[0;32m     44\u001b[0m })\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🚀 Entraînement en cours...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Évaluation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32mF:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\transformers\\modeling_tf_utils.py:1209\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1208\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mF:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mF:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mF:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mF:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mF:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mF:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32mF:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mF:\\Users\\Djamel\\AppData\\Local\\anaconda3\\envs\\Module_7\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.lightgbm\n",
    "import mlflow.tensorflow\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from utils import load_data_tfidf, load_data_use\n",
    "from models.use_model import train_use\n",
    "from models.lstm_model import train_lstm\n",
    "from models.bert_model import build_and_train_bert\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, log_loss, roc_auc_score\n",
    "\n",
    "# Chargement du fichier YAML\n",
    "def load_config():\n",
    "    config_path = \"config.yml\"\n",
    "    with open(config_path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "# Fonction d'entraînement générique pour les modèles scikit-learn\n",
    "def train_model_sklearn(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Prédictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Métriques\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        logloss = log_loss(y_test, y_proba)\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "        # Logging\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"log_loss\", logloss)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "\n",
    "        print(f\"✅ {model_name} terminé avec précision={accuracy:.2f} | F1={f1:.2f} | AUC={roc_auc:.2f}\")\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    config = load_config()\n",
    "\n",
    "    # === 1. Données TF-IDF pour les modèles classiques ===\n",
    "    X_train_tfidf, X_test_tfidf, y_train, y_test, _ = load_data_tfidf()\n",
    "\n",
    "    # === 2. Random Forest ===\n",
    "    rf_params = {k: v[0] for k, v in config[\"grid_search\"][\"random_forest\"].items()}\n",
    "    rf_model = RandomForestClassifier(**rf_params)\n",
    "    train_model_sklearn(rf_model, \"RandomForest\", X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "\n",
    "    # === 3. Logistic Regression ===\n",
    "    logreg_params = {k: v[0] for k, v in config[\"grid_search\"][\"logistic_regression\"].items()}\n",
    "    logreg_model = LogisticRegression(**logreg_params)\n",
    "    train_model_sklearn(logreg_model, \"LogisticRegression\", X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "\n",
    "    # === 4. LightGBM ===\n",
    "    lgbm_params = {k: v[0] for k, v in config[\"grid_search\"][\"lightgbm\"].items()}\n",
    "    lgbm_model = LGBMClassifier(**lgbm_params)\n",
    "    train_model_sklearn(lgbm_model, \"LightGBM\", X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "\n",
    "    # === 5. Universal Sentence Encoder ===\n",
    "    X_train_use, X_test_use, y_train_use, y_test_use = load_data_use()\n",
    "    train_use(config[\"use\"], X_train_use, X_test_use, y_train_use, y_test_use)\n",
    "\n",
    "    # === LSTM ===\n",
    "    train_lstm()\n",
    "\n",
    "\n",
    "# === Entraînement BERT ===\n",
    "\n",
    "print(\"📦 Modèle BERT\")\n",
    "build_and_train_bert()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf874b7f-27b8-4955-a49d-c1518793cc74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
