# Analyse de Sentiments gr√¢ce au Deep Learning avec l'approche MLOps

> Cet article est disponible en ligne : [Blog](https://github.com/Aragor85/mlflow_project/blob/analyse_sentiments/docs/Analyse_de_sentiments.md)

![Les sentiments a travers les Tweet](images/Tweet.png)

*Cet article a √©t√© r√©dig√© dans le cadre du projet : R√©alisez une analyse de sentiments gr√¢ce au Deep Learning du parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer). Les donn√©es utilis√©es sont issues du jeu de donn√©es open source [Sentiment140](https://www.kaggle.com/datasets/kazanova/sentiment140). Le code source complet est disponible sur [(https://github.com/Aragor85/mlflow_projectGitHub)]*

> üéì OpenClassrooms ‚Ä¢ Parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) | üëã *√âtudiant* : Djamel FERGUEN


## üåê Contexte et probl√©matique m√©tier 

Ce projet s'inscrit dans un sc√©nario professionnel o√π j'interviens en tant qu'ing√©nieur IA chez MIC (Marketing Intelligence Consulting), entreprise de conseil sp√©cialis√©e sur les probl√©matiqus de marketing digital.

Notre client,  **Air Paradis** (compagnie a√©rienne), souhaite **anticiper les bad buzz sur les r√©seaux sociaux**. La mission consiste √† d√©velopper un produit IA permettant de pr√©dire le sentiment associ√© √† un tweet, afin d'am√©liorer son image de marque en ligne.

## ‚ö° Mission

> D√©velopper un mod√®le d'IA permettant de pr√©dire le sentiment associ√© √† un tweet.

Cr√©er un prototype fonctionnel d'un mod√®le d'analyse de sentiments pour tweets selon trois approches diff√©rentes :

1. **Mod√®le simple** : Approche classique (r√©gression logistique,Randomforest,LightGBM) pour une pr√©diction rapide
2. **Mod√®le avanc√©** : Utilisation de r√©seaux de neurones profonds avec diff√©rents word embeddings ( USE, Bidirectional_LSTM et BERT)
3. **Mod√®le avanc√© BERT** : Le mod√®le BERT est bien int√©gr√© dans le projet. Cependant, en raison de limitations mat√©rielles (notamment l'absence de GPU et une configuration uniquement sur CPU), l'entra√Ænement s'est av√©r√© extr√™mement lent. Face √† un temps de calcul estim√© √† 10 heures par Epoch, j'ai d√©cid√© d'interrompre l'ex√©cution du mod√®le

Cette mission implique √©galement la mise en place d'une **d√©marche MLOps compl√®te pour le deploiment sur le Cloud** :

- Utilisation de **MLFlow pour le tracking des exp√©rimentations et le stockage des mod√®les**.
- Cr√©ation d'un **pipeline de d√©ploiement continu (Git + Github + plateforme Cloud Azure)**.
- Int√©gration de **tests unitaires automatis√©s**.
- Mise en place d'un **suivi de performance du mod√©le en production** via Azure A[pplication Insight](https://learn.microsoft.com/fr-fr/azure/azure-monitor/app/app-insights-overview).

## üîß Environnement technique

- **Distribution** : Anaconda
- **Langages** : Python ver. 3.10
- **Biblioth√®ques ML/DL** : Scikit-learn, TensorFlow/Keras, Transformers
- **MLOps** : MLFlow, Git, GitHub Actions
- **Backend** : FastAPI
- **Frontend** : Streamlit   
- **Monitoring** : Azure Application Insight
- **Traitement texte** : NLTK, Word Embeddings

## üèõÔ∏è Structure du projet

```
```

![Les sentiments a travers les Tweet](images/UML.png)


## üìë M√©thodologie et donn√©es

### Le jeu de donn√©es Sentiment140

Pour ce projet, nous avons utilis√© le jeu de donn√©es open source Sentiment140, qui contient 1,6 million de tweets annot√©s (n√©gative ou positive). Ce dataset comprend six champs principaux :

- **target** : la polarit√© du tweet (0 = n√©gatif, 1 = positif)
- **ids** : l'identifiant du tweet
- **date** : la date du tweet
- **flag** : une requ√™te √©ventuelle
- **user** : l'utilisateur ayant post√© le tweet
- **text** : le contenu textuel du tweet

J'ai choisi de r√©duire la taille du dataset a 16 000 tweets pour la suite du projet en raison de limitations mat√©rielles (notamment l'absence de GPU et une configuration uniquement sur CPU), l'entra√Ænement s'est av√©r√© extr√™mement lent.

### Analyse exploratoire des donn√©es Sentiment140

Notre analyse exploratoire a r√©v√©l√© des caract√©ristiques distinctives importantes entre les tweets positifs et n√©gatifs :

- 50% de tweets positifs
- 50% de tweets n√©gatifs

√©quilibr√©s pas de smote 

### Pr√©traitement des donn√©es textuelles

Dans ce projet, le pr√©traitement des donn√©es textuelles est une √©tape essentielle pour garantir des pr√©dictions fiables. Il consiste √† nettoyer les tweets en supprimant les caract√®res sp√©ciaux, les URLs, les mentions et les stop words. Les textes sont ensuite normalis√©s (minuscules, lemmatisation) pour r√©duire la variance linguistique. Cette √©tape permet d‚Äôobtenir des repr√©sentations textuelles plus coh√©rentes avant l‚Äôentra√Ænement des mod√®les de classification.
 
## üß† Approches de mod√©lisation

Pour r√©pondre √† la demande d'Air Paradis, nous avons d√©velopp√© et compar√© 5 approches de mod√©lisation distinctes, de la plus simple √† la plus avanc√©e.

### Mod√®le classique
- Logistic regression
- Randomforest
- LightGBM

Notre premi√®re approche s'est bas√©e sur des techniques classiques de machine learning, combinant une vectorisation du texte avec un classifieur traditionnel :

1. **Vectorisation** : transformation des textes en repr√©sentations num√©riques via TF-IDF (Term Frequency-Inverse Document Frequency)
2. **Classification** : utilisation d'un Randomforest,LightGBM ou R√©gression Logistique pour pr√©dire le sentiment

Cette approche pr√©sente plusieurs avantages :
- Rapidit√© d'entra√Ænement et d'inf√©rence
- Faible empreinte m√©moire
- Bonne interpr√©tabilit√© des r√©sultats

Malgr√© sa simplicit√©, ce mod√®le a atteint une pr√©cision (accuracy) de 73% sur notre jeu de test, ce qui constitue une base solide pour la d√©tection de sentiments.

### Mod√®les avanc√© (r√©seaux de neurones avec word embeddings)

**Universal Sentence Encoder (USE)** : Le mod√®le USE encode des phrases en vecteurs de grande dimension capturant leur sens global. Il est rapide, l√©ger et bien adapt√© aux t√¢ches de classification de texte avec peu de ressources.

**Bidirectional LSTM (BiLSTM)** Le BiLSTM traite les s√©quences de mots dans les deux directions (avant et arri√®re), capturant ainsi le contexte complet d‚Äôune phrase. Il est particuli√®rement performant pour comprendre la structure grammaticale des textes.

![Courbes de Loss & Accuracy](images/lstm_training_curves.png)

**DistilBERT**: DistilBERT est une version plus l√©g√®re de BERT, conservant 95 % de sa performance tout en √©tant plus rapide. Il est entra√Æn√© sur des milliards de mots, ce qui le rend tr√®s pr√©cis pour l‚Äôanalyse de sentiments.

### Comparaison des performances des mod√®les

Voici un r√©capitulatif des performances obtenues avec nos diff√©rentes approches :

| Mod√®le | Accuracy |F1-Score | AUC | Temps d'entra√Ænement |
|--------|----------|---------|-----|----------------------|
| Randomforest + TF-IDF | 0,71 | 0,73% | 0,79 | 34 secondes |
| R√©gression Logistique + TF-IDF | 0,71  | 0,70 | 0,77 | 10 secondes |
| LightGBM + TF-IDF | 0,73 | 0,74 | 0,81 | 13 secondes |
| USE | 0,77 | 0,75 | 0,85 | 24 secondes |
| Bidirectional_LSTM | 0,71 | 0,72 | 0,77 | 14,5 min |
| BERT | -- | -- | -- | ~40 heures |

## ‚öôÔ∏è Mise en ≈ìuvre du MLOps

### Principes du MLOps

**Le MLOps (Machine Learning Operations) est une m√©thodologie qui vise √† standardiser et √† automatiser le cycle de vie des mod√®les de machine learning**, de leur d√©veloppement √† leur d√©ploiement en production. Pour ce projet, nous avons mis en ≈ìuvre plusieurs principes cl√©s du MLOps :

1. **Reproductibilit√©** : environnement de d√©veloppement versionn√© et document√©
2. **Automatisation** : pipeline de d√©ploiement continu
3. **Monitoring** : suivi des performances du mod√®le en production
4. **Am√©lioration continue** : collecte de feedback et r√©entra√Ænement p√©riodique

Cette approche nous a permis de cr√©er une solution robuste et √©volutive pour Air Paradis.

### Tracking des exp√©rimentations avec MLFlow

Pour assurer une gestion efficace des exp√©rimentations, nous avons utilis√© [MLFlow](https://mlflow.org/docs/latest/index.html), un outil open-source sp√©cialis√© dans le **suivi et la gestion des mod√®les de machine learning** :

1. **Tracking des m√©triques** : pour chaque exp√©rimentation, nous avons enregistr√© automatiquement les param√®tres du mod√®le, les m√©triques de performance (accuracy, F1-score, pr√©cision, rappel) et les artefacts g√©n√©r√©s
2. **Centralisation des mod√®les** : tous les mod√®les entra√Æn√©s ont √©t√© stock√©s de mani√®re centralis√©e avec leurs m√©tadonn√©es
3. **Visualisation** : l'interface utilisateur de MLFlow nous a permis de comparer visuellement les diff√©rentes exp√©rimentations

![Mlflow UI](images/mlflow_UI.png)

Cette approche nous a permis de tracer l'√©volution de nos mod√®les et de s√©lectionner le plus performant pour le d√©ploiement.

Pour le d√©ploiement en production, nous avons retenu le mod√®le **USE**, qui offre le meilleur compromis entre performance et ressources requises. Et plus adapt√© √† un d√©ploiement sur une infrastructure Cloud gratuite.

## üíª Interface utilisateur

### Architecture de l'application

Pour l'interfacage j'ai choisi FastAPI en Backend, car il est est rapide, moderne, et facile √† int√©grer avec des mod√®les ML gr√¢ce √† son support natif.


### Fonctionnalit√©s de l'interface Backend

- **Backend (FastAPI)** :
   - API REST exposant le mod√®le d'analyse de sentiments
   - Endpoints pour la pr√©diction individuelle et par lots
   - Syst√®me de feedback et de monitoring
   - T√©l√©chargement automatique des artefacts du mod√®le depuis MLFlow

  ![Page /docs du serveur FastAPI](images/BackEnd_FastAPi_1.png)
  ![Page /docs du serveur FastAPI](images/BackEnd_FastAPi_2.png)


### Fonctionnalit√©s de l'interface utilisateur

**Streamlit** est parfait pour l‚Äôinterface utilisateur,car il permet de cr√©er rapidement des applications web interactives en Python. Il s‚Äôint√®gre facilement avec les mod√®les ML pour afficher pr√©dictions, graphiques et r√©sultats en temps r√©el.

  ![Interface_utilisateur](images/API_Streamlit_local.png)


## üîÑ Pipeline de d√©ploiement continu

Pour automatiser le d√©ploiement de notre mod√®le, nous avons mis en place un **pipeline CI/CD (Int√©gration Continue / D√©ploiement Continu)** avec les composants suivants :

1. **Versionnement du code** : utilisation de Git pour le contr√¥le de version
2. **GitHub Actions** : automatisation des tests et du d√©ploiement √† chaque push sur la branche (analyse_sentiments)
3. **D√©ploiement sur Azure** : plateforme Cloud pour h√©berger notre API de pr√©diction de sentiments


### Tests unitaires automatis√©s

Pour garantir la fiabilit√© de notre solution, nous avons impl√©ment√© des **tests unitaires automatis√©s** couvrant les aspects critiques :

1. **Test du endpoint** : V√©rifie que l'API r√©pond correctement avec un code 200 et confirme que le statut retourn√© est "ok". Le mod√®le est charg√© correctement.
2. **Test du endpoint de pr√©diction** : S'assure que l'API traite correctement les requ√™tes POST sur `/predict`, accepte un texte √† analyser et renvoie un r√©sultat contenant les champs "sentiment".

### GitHub Actions 

Le d√©ploiement est enti√®rement automatis√© gr√¢ce √† **GitHub Actions** :

1. **D√©clenchement** : √Ä chaque commit/push sur la branche(analyse_sentiments), GitHub Actions lance le workflow.
2. **Tests automatis√©s** : Le workflow ex√©cute tous les tests unitaires.
3. **D√©ploiement conditionnel** : Uniquement si les tests r√©ussissent, l'application est d√©ploy√©e automatiquement sur Azure .[Test API ](https://analyse-de-sentiments.azurewebsites.net/)

#### Cr√©ation du workflow GitHub Actions

Pour la cr√©ation du workflow GitHub Actions, nous cr√©ons un fichier `.github/workflows/analyse_sentiments_module-7.yml`

#### Configuration des secrets GitHub

Le workflow **GitHub Actions** a besoin d'acc√©der aux **variables d'environnement**. Nous avons donc renseigner les "secrets" n√©cessaires. Dans notre d√©p√¥t GitHub, nous allons dans "Settings" > "Secrets and variables" > "Actions", puis nous cliquons sur "New repository secret". Nous ajoutons les secrets suivants:

!["New repository secret" dans Github](images/Github_Secrets_Actions.png)


### D√©ploiement sur Azure

Pour le d√©ploiement de notre solution, nous avons choisi [Azure](https://azure.microsoft.com/) pour plusieurs raisons :

1. **Plan gratuit** : conforme √† la demande de limiter les co√ªts pour ce prototype
2. **Int√©gration avec GitHub** : facilite le d√©ploiement continu avec GitHub Actions
3. **Scalabilit√©** : possibilit√© d'√©voluer si le projet est approuv√© pour la production

#### Configuration Azure

Notre application utilise les fichiers de configuration suivants pour Azure :

- **Procfile** : `gunicorn app.main:app --workers 1 --worker-class uvicorn.workers.UvicornWorker --bind=0.0.0.0:8000`
- **runtime.txt** : `python-3.10`
- **requirements.txt** : Liste de toutes les d√©pendances n√©cessaires

Les variables d'environnement sur Azure incluent :
- `MLFLOW_TRACKING_URI` : URI du serveur MLflow
- `RUN_ID` : Identifiant du run MLflow du mod√®le d√©ploy√©
- `INSTRUMENTATION_KEY` : Cl√© pour Azure voir xxxxxxx.yml

#### Docker **Il faut parler 

pour d√©ployer une interface utilisateur Streamlit et tout le projet sur Azure :

- **Isolation & portabilit√©** : un conteneur regroupe toute l'application (FastAPI + Streamlit + d√©pendances) dans un environnement coh√©rent et r√©utilisable.

- **D√©ploiement** : ACR permet de stocker et g√©rer les images Docker, pr√™tes √† √™tre d√©ploy√©es sur Azure App Service.

- **Compatibilit√© Cloud** : Azure App Service peut ex√©cuter directement une image Docker depuis ACR, sans se soucier des d√©pendances.

- **D√©ploiement automatis√©** : GitHub Actions peut builder, pousser l‚Äôimage sur ACR et la d√©ployer automatiquement.

- **Multi-services unifi√©s** : Streamlit (UI) et FastAPI (backend) peuvent tourner ensemble dans un m√™me conteneur, sur un seul port expos√©.

- **Scalabilit√© & maintenance** : plus simple de mettre √† jour ou r√©pliquer l‚Äôapplication avec une nouvelle version du conteneur.

### Exemple d'ex√©cution et d√©ploiement r√©ussis

La capture d'√©cran suivante indique que le d√©ploiement est r√©ussi sur **Azure**.

![GitHub Actions](images/Github_Build.png)
![GitHub Actions](images/Github_deployment.png)


### Avantages de notre pipeline CI/CD

Notre pipeline de d√©ploiement continu offre plusieurs avantages significatifs :

1. **Automatisation du deploiment** : chaque modification pouss√©e sur GitHub d√©clenche automatiquement les √©tapes de test, de packaging, et de d√©ploiement de l'API FastAPI contenant le mod√®le d'analyse de sentiments.
2. **Fiabilit√© grace aux tests automatis√©s** : Les tests unitaires garantissent la validit√© du code √† chaque mise √† jour.
3. **Tra√ßabilit√©** : Chaque d√©ploiement est associ√© a un commit Git pr√©cis pour faciliter le suivi et evolutions du mod√©le
4. **Feedback rapide pour les developpeurs** : en cas d'erreur des tests ou du deploiment, une notification est envoy√© pour corrigier rapidement le bug


## üì° Suivi de la performance en production

### Suivi des performances avec Azure Application Insights

Afin d'analyser le comportement de notre mod√®le en production, nous avons int√©gr√© Azure Application Insights pour analyser les peformances en temps r√©el. Cette solution nous offre :

- collecte en temps r√©el des m√©triques de performance de l‚ÄôAPI.

- Enregistrement sp√©cifique des actions ou erreurs li√©es aux pr√©dictions du mod√®le.

- Tableaux de bord interactifs pour visualiser et analyser les performances sur la dur√©e.

### Collecte de feedback utilisateur

Nous avons mis en place un syst√®me structur√© de retour utilisateur permettant d‚Äô√©valuer la  les pr√©dictions si elles sont bonnes ou mauvaises :

- Chaque utilisateur peut confirmer ou infirmer la pr√©diction g√©n√©r√©e par le mod√®le.

- L'enregistrement du tweet, de la pr√©diction du mod√®le et la correction utilisateur sur l'interface Streamlit si n√©cessaire.

- L‚Äôensemble des retours est centralis√© dans Azure Application Insights, facilitant l‚Äôanalyse et l‚Äôam√©lioration continue du mod√®le.

Pour consulter les **feedbacks de tweets incorrectement pr√©dits**, il suffit d'ex√©cuter la commande suivante : 


![Capture d'√©cran d'un requ√™te](images/Requ√™tes.png)
------------------------------------------------------------

------------------------------------------------------------
![Feedbacks de tweets ](images/Requ√™tes_logs.png)

Cette m√©thode permet de **constituer progressivement une base d'exemples difficiles √† traiter**. Ces tweets mal classifi√©s sont tr√®s utiles car ils r√©v√®lent **les faiblesses sp√©cifiques du mod√®le**. En les collectant syst√©matiquement, on construit **un jeu de donn√©es cibl√© sur les erreurs** du mod√®le. Cette m√©thode s'inscrit dans une d√©marche **d‚Äôapprentissage actif (active learning)**. Elle est plus **efficace** qu‚Äôun simple ajout al√©atoire de donn√©es, car elle concentre l‚Äôam√©lioration du mod√®le sur les cas **r√©ellement probl√©matiques**.

### Configuration des alertes automatiques

Nous avons mis en place un **syst√®me d'alertes automatiques** pour d√©tecter les d√©rives de performance du mod√®le.
Une alerte est d√©clench√©e si **trois erreurs de pr√©diction sont signal√©es en moins de 5 minutes**.
Lorsqu‚Äôune alerte est g√©n√©r√©e, **une notification par email** est envoy√©e aux responsables du projet.
Toutes les **alertes sont stocker** pour permettre une analyse a posteriori.
Ce syst√®me de **monitoring proactif** permet √† l‚Äô√©quipe d‚Äôintervenir avant que les erreurs ne se multiplient.

<table>
  <tr>
    <td><img src="images/Alert_email_1.png" width="350"/></td>
    <td><img src="images/Alert_email_2.png" width="350"/></td>
  </tr>
  <tr>
    <td align="center">Alerte - Email 1</td>
    <td align="center">Alerte - Email 2</td>
  </tr>
</table>


Pour am√©liorer le mod√©le,il faut **d√©finir une periode** pour analyser les **tweets mal classifi√©s** pour d√©tecter des motifs r√©currents.
Les exemples identifi√©s sont ensuite ajout√©s au dataset d'entra√Ænement pour **enrichir le mod√®le** en se basant sur les conversation concernant la compagnie Air Paradis.
Enfin, **un r√©entra√Ænement et d√©ploiement automatis√©** via le pipeline CI/CD.

## Conclusion

Ce projet a permis de cr√©er un prototype d‚Äôanalyse de sentiments adapt√© aux besoins d‚ÄôAir Paradis. Le mod√®le USE a atteint 82% de pr√©cision et est int√©gr√© dans une API d√©ploy√©e sur Azure.

Une interface ergonomique avec Streamlit facilite son usage pour les √©quipes marketing. De plus, un monitoring via Application Insights permet de suivre les pr√©dictions et d√©tecter les erreurs.

Ce syst√®me aide Air Paradis √† d√©tecter rapidement les signaux n√©gatifs sur les r√©seaux sociaux et √† prot√©ger son image.

Cet outil [API](https://analyse-de-sentiments.azurewebsites.net) renforce la r√©activit√© de l'√©quipe de marketing de l'entreprise **Air Paradis**.

En r√©sum√©, cette solution illustre le potentiel de l‚ÄôIA et du MLOps pour am√©liorer la gestion de la e-r√©putation dans les r√©seaux sociaux.

