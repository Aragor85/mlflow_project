# Analyse de Sentiments gr√¢ce au Deep Learning avec l'approche MLOps

> Cet article est disponible en ligne : [xxxxxxxxxxxxx](xxxxxxxxxxxxxxxx)

![Les sentiments a travers les Tweet](images/Tweet.png)

*Cet article a √©t√© r√©dig√© dans le cadre du projet : R√©alisez une analyse de sentiments gr√¢ce au Deep Learning du parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer). Les donn√©es utilis√©es sont issues du jeu de donn√©es open source [Sentiment140](https://www.kaggle.com/datasets/kazanova/sentiment140). Le code source complet est disponible sur [(https://github.com/Aragor85/mlflow_projectGitHub)]*

> üéì OpenClassrooms ‚Ä¢ Parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) | üëã *√âtudiant* : Djamel FERGUEN

![API: Analyse des sentiments a travers les Tweet](images/Tweet.png)


## üåê Contexte et probl√©matique m√©tier 

Ce projet s'inscrit dans un sc√©nario professionnel o√π j'interviens en tant qu'ing√©nieur IA chez MIC (Marketing Intelligence Consulting), entreprise de conseil sp√©cialis√©e sur les probl√©matiqus de marketing digital.

Notre client,  **Air Paradis** (compagnie a√©rienne), souhaite **anticiper les bad buzz sur les r√©seaux sociaux**. La mission consiste √† d√©velopper un produit IA permettant de pr√©dire le sentiment associ√© √† un tweet, afin d'am√©liorer son image de marque en ligne.

## ‚ö° Mission

> D√©velopper un mod√®le d'IA permettant de pr√©dire le sentiment associ√© √† un tweet.

Cr√©er un prototype fonctionnel d'un mod√®le d'analyse de sentiments pour tweets selon trois approches diff√©rentes :

1. **Mod√®le simple** : Approche classique (r√©gression logistique,Randomforest,LightGBM) pour une pr√©diction rapide
2. **Mod√®le avanc√©** : Utilisation de r√©seaux de neurones profonds avec diff√©rents word embeddings ( USE, Bidirectional_LSTM et BERT)
3. **Mod√®le avanc√© BERT** : Le mod√®le BERT est bien int√©gr√© dans le projet. Cependant, en raison de limitations mat√©rielles (notamment l'absence de GPU et une configuration uniquement sur CPU), l'entra√Ænement s'est av√©r√© extr√™mement lent. Face √† un temps de calcul estim√© √† 10 heures par Epoch, j'ai d√©cid√© d'interrompre l'ex√©cution du mod√®le

Cette mission implique √©galement la mise en place d'une **d√©marche MLOps compl√®te pour le deploiment sur le Cloud** :

- Utilisation de **MLFlow pour le tracking des exp√©rimentations et le stockage des mod√®les**.
- Cr√©ation d'un **pipeline de d√©ploiement continu (Git + Github + plateforme Cloud Azure)**.
- Int√©gration de **tests unitaires automatis√©s**.
- Mise en place d'un **suivi de performance du mod√©le en production** via Azure A[pplication Insight](https://learn.microsoft.com/fr-fr/azure/azure-monitor/app/app-insights-overview).

## üîß Environnement technique

- **Distribution** : Anaconda ver. XX.XX
- **Langages** : Python ver. 3.10
- **Biblioth√®ques ML/DL** : Scikit-learn, TensorFlow/Keras, Transformers (BERT),  **Ajoute USE LSTM,......**
- **MLOps** : MLFlow, Git, GitHub Actions
- **Backend** : FastAPI
- **Frontend** : Next.js / React   
- **Monitoring** : Azure Application Insight
- **Traitement texte** : NLTK, Word Embeddings

## üèõÔ∏è Structure du projet

```
üì¶ mlflow_project/
‚î£‚îÅ‚îÅ üìÇ app/
‚îÉ   ‚î£‚îÅ‚îÅ üìÇ model/                                   # Backend API de pr√©diction
‚îÉ       ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml      # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights
‚îÉ       ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml      # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights
‚îÉ       ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml      # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights
‚îÉ       ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml      # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights
‚îÉ       ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml      # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights
‚îÉ   ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml          # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights
‚îÉ   ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml          # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights
‚îÉ   ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml          # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights
‚îÉ   ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml          # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights

‚î£‚îÅ‚îÅ üìÇ .github/
‚îÉ   ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml          # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights

‚î£‚îÅ‚îÅ üìÇ data/
‚îÉ   ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml          # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights
‚î£‚îÅ‚îÅ üìÇ docs/
‚îÉ   ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml          # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights
‚î£‚îÅ‚îÅ üìÇ images/
‚îÉ   ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml          # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights
‚î£‚îÅ‚îÅ üìÇ mlruns/
‚îÉ   ‚î£‚îÅ‚îÅ üìÇ 0/                                       # Backend API de pr√©diction
‚îÉ       ‚îó‚îÅ‚îÅ üìÇ frontend/                            # Application Next.js
‚îÉ       ...
        ‚îó‚îÅ‚îÅ üìÇ frontend/                            # Application Next.js
‚îÉ       
‚î£‚îÅ‚îÅ üìÇ models/
‚îÉ   ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml          # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights
    ...  
‚îÉ   ‚îó‚îÅ‚îÅ üìÉ analyse_sentiments_module-7.yml          # Guide de suivi des feedback utilisateur et des alertes avec Azure Application insights
‚îó‚îÅ‚îÅ üìÇ notebooks/                                   # Notebooks Jupyter pour l'analyse et mod√®les
    ‚î£‚îÅ‚îÅ üìù 01_Analyse_exploratoire.ipynb            # Exploration et visualisation des donn√©es
    
‚îó‚îÅ‚îÅ üìù 04_Modele_BERT.ipynb                         # DistilBERT pour analyse de sentiment
‚îó‚îÅ‚îÅ üìù 04_Modele_BERT.ipynb                         # DistilBERT pour analyse de sentiment
‚îó‚îÅ‚îÅ üìù 04_Modele_BERT.ipynb                         # DistilBERT pour analyse de sentiment
‚îó‚îÅ‚îÅ üìù 04_Modele_BERT.ipynb                         # DistilBERT pour analyse de sentiment
‚îó‚îÅ‚îÅ üìù 04_Modele_BERT.ipynb                         # DistilBERT pour analyse de sentiment

## üìî Notebooks du projet

- [üìä Notebook 1 : Analyse exploratoire des donn√©es]  link to notebook

## üß≠ Guides

- Help pour utilisation de l'API !!!! 

## üìë M√©thodologie et donn√©es

### Le jeu de donn√©es Sentiment140

Pour ce projet, nous avons utilis√© le jeu de donn√©es open source Sentiment140, qui contient 1,6 million de tweets annot√©s (n√©gative ou positive). Ce dataset comprend six champs principaux :

- **target** : la polarit√© du tweet (0 = n√©gatif, 1 = positif)
- **ids** : l'identifiant du tweet
- **date** : la date du tweet
- **flag** : une requ√™te √©ventuelle
- **user** : l'utilisateur ayant post√© le tweet
- **text** : le contenu textuel du tweet

J'ai choisi de r√©duire la taille du dataset a 16 000 tweets pour la suite du projet (configuration materi√©ls).

!!!!  reduction de la taille du dataset 

### Analyse exploratoire des donn√©es Sentiment140

Notre analyse exploratoire a r√©v√©l√© des caract√©ristiques distinctives importantes entre les tweets positifs et n√©gatifs :

- XX%  de tweets positifs
- XX%  de tweets n√©gatifs

√©quilibr√©s pas de smote 

### Pr√©traitement des donn√©es textuelles

Un petit paragraphe pour d√©crire et surtout v√©rification ce que j'ai fait dans le premier Notebook (strat√©gie de pr√©traitement en 3 ou 4 points cl√©s) :   

## üß† Approches de mod√©lisation

Pour r√©pondre √† la demande d'Air Paradis, nous avons d√©velopp√© et compar√© 5 approches de mod√©lisation distinctes, de la plus simple √† la plus avanc√©e.

### Mod√®le classique
- Logistic regression
- Randomforest
- LightGBM


Notre premi√®re approche s'est bas√©e sur des techniques classiques de machine learning, combinant une vectorisation du texte avec un classifieur traditionnel :

1. **Vectorisation** : transformation des textes en repr√©sentations num√©riques via TF-IDF (Term Frequency-Inverse Document Frequency)
2. **Classification** : utilisation d'un Randomforest,LightGBM ou R√©gression Logistique pour pr√©dire le sentiment

Cette approche pr√©sente plusieurs avantages :
- Rapidit√© d'entra√Ænement et d'inf√©rence
- Faible empreinte m√©moire
- Bonne interpr√©tabilit√© des r√©sultats

Malgr√© sa simplicit√©, ce mod√®le a atteint une pr√©cision (accuracy) de XX% sur notre jeu de test, ce qui constitue une base solide pour la d√©tection de sentiments.

### Mod√®les avanc√© (r√©seaux de neurones avec word embeddings)

- USE
- Bidirectional_LSTM
- distilbert-base-uncased

Pour notre deuxi√®me approche, nous avons explor√© les techniques de deep learning avec des embeddings de mots et des r√©seaux de neurones r√©currents :

Un petit paragraphe pour d√©crire le pr√©traitement en 3 ou 4 points cl√©s) :   

Faut-il ajouter quelques morceau de code des differents models ? 


L'architecture de notre mod√®le LSTM comprend :

Un petit descrptif avec graphe Accuracy et loss ( Test 10 epoch et non pas 4 comme dans mlflow UI )
Ajoute courbe d'apprentissage voir mlruns 

**L'architecture de notre mod√®le USE comprend** :

**L'architecture de notre mod√®le BERT comprend** :

Les r√©sultats de l'entra√Ænement montrent une progression constante avec de l'accuracyes/48j9lz9bh84os9nkp2bz.png)

Cette approche plus sophistiqu√©e nous a permis d'atteindre une pr√©cision de 81,8% sur l'ensemble de validation, avec un score de 85,2% sur le jeu d'entra√Ænement, surpassant ainsi le mod√®le simple.

### Mod√®le BERT (approche transformer)

Pour notre troisi√®me approche, nous avons explor√© l'√©tat de l'art en NLP en utilisant BERT (Bidirectional Encoder Representations from Transformers) :

1. **Mod√®le pr√©-entra√Æn√©** : nous avons utilis√© DistilBERT, une version all√©g√©e et distill√©e de BERT, pour r√©duire les co√ªts de calcul tout en maintenant des performances √©lev√©es
2. **Fine-tuning** : nous avons affin√© le mod√®le sur notre jeu de donn√©es sp√©cifique d'analyse de sentiments

Pour cette approche, nous avons utilis√© le mod√®le `DistilBertForSequenceClassification` de la biblioth√®que Hugging Face, qui est sp√©cifiquement con√ßu pour les t√¢ches de classification de s√©quences textuelles :

```S
```


### Comparaison des performances des mod√®les

Voici un r√©capitulatif des performances obtenues avec nos diff√©rentes approches :

| Mod√®le | Pr√©cision (Accuracy) | F1-Score | Temps d'entra√Ænement | Taille du mod√®le |
|--------|----------------------|----------|---------------------|-----------------|
| R√©gression Logistique + TF-IDF | xx,xx% | xx,xx | xx secondes | ~xx MB |
| Randomforest + TF-IDF | xx,xx% | xx,xx | xx secondes | ~xx MB |
| LightGBM + TF-IDF | xx,xx% | xx,xx | xx secondes | ~xx MB |
| USE | xx,xx% | xx,xx | xx secondes (GPU) | ~xx MB |
| Bidirectional_LSTM | xx,xx% | xx,xx | xx min | ~xx MB |
| BERT | --% | -- | -- | ~--- MB |

Pour le d√©ploiement en production, nous avons retenu le mod√®le **USE**, qui offre le meilleur compromis entre performance et ressources requises.  et plus adapt√© √† un d√©ploiement sur une infrastructure Cloud gratuite.

## ‚öôÔ∏è Mise en ≈ìuvre du MLOps

### Principes du MLOps

**Le MLOps (Machine Learning Operations) est une m√©thodologie qui vise √† standardiser et √† automatiser le cycle de vie des mod√®les de machine learning**, de leur d√©veloppement √† leur d√©ploiement en production. Pour ce projet, nous avons mis en ≈ìuvre plusieurs principes cl√©s du MLOps :

1. **Reproductibilit√©** : environnement de d√©veloppement versionn√© et document√©
2. **Automatisation** : pipeline de d√©ploiement continu
3. **Monitoring** : suivi des performances du mod√®le en production
4. **Am√©lioration continue** : collecte de feedback et r√©entra√Ænement p√©riodique

Cette approche nous a permis de cr√©er une solution robuste et √©volutive pour Air Paradis.

### Tracking des exp√©rimentations avec MLFlow

Pour assurer une gestion efficace des exp√©rimentations, nous avons utilis√© [MLFlow](https://mlflow.org/docs/latest/index.html), un outil open-source sp√©cialis√© dans le **suivi et la gestion des mod√®les de machine learning** :

1. **Tracking des m√©triques** : pour chaque exp√©rimentation, nous avons enregistr√© automatiquement les param√®tres du mod√®le, les m√©triques de performance (accuracy, F1-score, pr√©cision, rappel) et les artefacts g√©n√©r√©s
2. **Centralisation des mod√®les** : tous les mod√®les entra√Æn√©s ont √©t√© stock√©s de mani√®re centralis√©e avec leurs m√©tadonn√©es
3. **Visualisation** : l'interface utilisateur de MLFlow nous a permis de comparer visuellement les diff√©rentes exp√©rimentations

![photo mlflow UI avec adresse local 127.0.](images/xxxx.png)

Cette approche nous a permis de tracer l'√©volution de nos mod√®les et de s√©lectionner le plus performant pour le d√©ploiement.

## üíª Interface utilisateur

### Architecture de l'application

Pour l'interfacage j'ai choisi FastAPI en Backend ( pourquoi ? voir dans la recherche d'info word ) :

![Page /docs du serveur FastAPI](images/ printscreen FastAPI.png)

- **Backend (FastAPI)** :
   - API REST exposant le mod√®le d'analyse de sentiments
   - Endpoints pour la pr√©diction individuelle et par lots
   - Syst√®me de feedback et de monitoring
   - T√©l√©chargement automatique des artefacts du mod√®le depuis MLFlow



## üîÑ Pipeline de d√©ploiement continu

Pour automatiser le d√©ploiement de notre mod√®le, nous avons mis en place un **pipeline CI/CD (Int√©gration Continue / D√©ploiement Continu)** avec les composants suivants :

1. **Versionnement du code** : utilisation de Git pour le contr√¥le de version
2. **GitHub Actions** : automatisation des tests et du d√©ploiement √† chaque push sur la branche (analyse_sentiments)
3. **D√©ploiement sur Azure** : plateforme Cloud pour h√©berger notre API de pr√©diction de sentiments

### Tests unitaires automatis√©s

Pour garantir la fiabilit√© de notre solution, nous avons impl√©ment√© des **tests unitaires automatis√©s** couvrant les aspects critiques :

1. **Test du endpoint** : V√©rifie que l'API r√©pond correctement avec un code 200 et confirme que le statut retourn√© est "ok". Le mod√®le est charg√© correctement.
2. **Test du endpoint de pr√©diction** : S'assure que l'API traite correctement les requ√™tes POST sur `/predict`, accepte un texte √† analyser et renvoie un r√©sultat contenant les champs "sentiment".

![photo test API et anacondapowershell et si besoin mettre le lien du realise ](images/xxxx.png)

### GitHub Actions 

Le d√©ploiement est enti√®rement automatis√© gr√¢ce √† **GitHub Actions** :

1. **D√©clenchement** : √Ä chaque commit/push sur la branche(analyse_sentiments), GitHub Actions lance le workflow.
2. **Tests automatis√©s** : Le workflow ex√©cute tous les tests unitaires.
3. **D√©ploiement conditionnel** : Uniquement si les tests r√©ussissent, l'application est d√©ploy√©e automatiquement sur Azure .[Test API ](https://module-7-bgg7hvanhddthjh4.canadacentral-01.azurewebsites.net/docs)

#### Cr√©ation du workflow GitHub Actions

Pour la cr√©ation du workflow GitHub Actions, nous cr√©ons un fichier `.github/workflows/heroku-deploy.yml` √† la racine dont voici le contenu :
'''Mettre le code .yml important !!!!
'''
#### Configuration des secrets GitHub

Le workflow **GitHub Actions** a besoin d'acc√©der aux **variables d'environnement**. Nous avons donc renseigner les "secrets" n√©cessaires. Dans notre d√©p√¥t GitHub, nous allons dans "Settings" > "Secrets and variables" > "Actions", puis nous cliquons sur "New repository secret". Nous ajoutons les secrets suivants:

![photo "New repository secret" dans Github](images/xxxx.png)


### D√©ploiement sur Azure

Pour le d√©ploiement de notre solution, nous avons choisi [Azure](https://azure.microsoft.com/) pour plusieurs raisons :

1. **Plan gratuit** : conforme √† la demande de limiter les co√ªts pour ce prototype
2. **Int√©gration avec GitHub** : facilite le d√©ploiement continu avec GitHub Actions
3. **Scalabilit√©** : possibilit√© d'√©voluer si le projet est approuv√© pour la production
4. **R√©gion Europe** : conformit√© avec les exigences de localisation des donn√©es

#### Configuration Azure

Notre application utilise les fichiers de configuration suivants pour Azure :

- **Procfile** : `gunicorn app.main:app --workers 1 --worker-class uvicorn.workers.UvicornWorker --bind=0.0.0.0:8000`
- **runtime.txt** : `python-3.10`
- **requirements.txt** : Liste de toutes les d√©pendances n√©cessaires

Les variables d'environnement sur Azure incluent :
- `MLFLOW_TRACKING_URI` : URI du serveur MLflow
- `RUN_ID` : Identifiant du run MLflow du mod√®le d√©ploy√©
- `INSTRUMENTATION_KEY` : Cl√© pour Azure voir xxxxxxx.yml

### Exemple d'ex√©cution et d√©ploiement r√©ussis

La capture d'√©cran suivante indique les **tests ont √©t√© pass√©s avec succ√®s** et que le d√©ploiement est r√©ussi sur **Azure**.

![Capture d'√©cran d'un run GitHub Actions](images/xxxx.png)

### Avantages de notre pipeline CI/CD

Notre pipeline de d√©ploiement continu offre plusieurs avantages significatifs :

1. **Automatisation du deploiment** : chaque modification pouss√©e sur GitHub d√©clenche automatiquement les √©tapes de test, de packaging, et de d√©ploiement de l'API FastAPI contenant le mod√®le d'analyse de sentiments.
2. **Fiabilit√© grace aux tests automatis√©s** : Les tests unitaires garantissent la validit√© du code √† chaque mise √† jour.
3. **Tra√ßabilit√©** : Chaque d√©ploiement est associ√© a un commit Git pr√©cis pour faciliter le suivi et evolutions du mod√©le
4. **Feedback rapide pour les developpeurs** : en cas d'erreur des tests ou du deploiment, une notification est envoy√© pour corrigier rapidement le bug


## üì° Suivi de la performance en production

### Suivi des performances avec Azure Application Insights

Afin de surveiller le comportement de notre mod√®le en production, nous avons int√©gr√© Azure Application Insights, un outil puissant d‚Äôanalyse des performances. Cette solution nous offre :

  **Une t√©l√©m√©trie automatis√©e** : collecte en temps r√©el des m√©triques de performance de l‚ÄôAPI.

  **Des √©v√©nements personnalis√©s** : enregistrement sp√©cifique des actions ou erreurs li√©es aux pr√©dictions du mod√®le.

  **Des tableaux de bord interactifs** : pour visualiser et analyser les performances sur la dur√©e.

Cette int√©gration nous donne une vue compl√®te et en temps r√©el du comportement de notre mod√®le.

### Collecte de feedback utilisateur

Dans le cadre de notre d√©marche MLOps, nous avons mis en place un syst√®me structur√© de retour utilisateur permettant d‚Äô√©valuer la justesse des pr√©dictions :

**Interface de validation** : chaque utilisateur peut confirmer ou infirmer la pr√©diction g√©n√©r√©e par le mod√®le.

**Collecte d√©taill√©e** : enregistrement du tweet, de la pr√©diction du mod√®le et la correction utilisateur si n√©cessaire.

**Stockage unifi√©** : l‚Äôensemble des retours est centralis√© dans Azure Application Insights, facilitant l‚Äôanalyse et l‚Äôam√©lioration continue du mod√®le.

Pour consulter les **feedbacks de tweets incorrectement pr√©dits**, il suffit d'ex√©cuter la commande suivante : 

```kusto
xxxxxxxxxxxx
xxxxxxxxxxxxx
xxxxxxxxxxxxxx
```

![Feedbacks de tweets incorrectement pr√©dits ](images/dans-Applicationinsight-capture-image.png)

Cette m√©thode permet de **constituer progressivement une base d'exemples difficiles √† traiter**. Ces tweets mal classifi√©s sont tr√®s utiles car ils r√©v√®lent **les faiblesses sp√©cifiques du mod√®le**. En les collectant syst√©matiquement, on construit **un jeu de donn√©es cibl√© sur les erreurs** du mod√®le. Cette m√©thode s'inscrit dans une d√©marche **d‚Äôapprentissage actif (active learning)**. Elle est plus **efficace** qu‚Äôun simple ajout al√©atoire de donn√©es, car elle concentre l‚Äôam√©lioration du mod√®le sur les cas **r√©ellement probl√©matiques**.

### Configuration des alertes automatiques

Nous avons mis en place un **syst√®me d'alertes automatiques** pour d√©tecter les d√©rives de performance du mod√®le.
Une alerte est d√©clench√©e si **trois erreurs de pr√©diction sont signal√©es en moins de 5 minutes**.
Lorsqu‚Äôune alerte est g√©n√©r√©e, **une notification par email** est envoy√©e aux responsables du projet.
Toutes les **alertes sont stocker** pour permettre une analyse a posteriori.
Ce syst√®me de **monitoring proactif** permet √† l‚Äô√©quipe d‚Äôintervenir avant que les erreurs ne se multiplient.

![Capture de l'√©cran alertes de Azure Application Insights](images/dans-Applicationinsight-Alerte-capture-image.png)

Pour am√©liorer le mod√©le,il faut **d√©finir une periode** pour analyser les **tweets mal classifi√©s** pour d√©tecter des motifs r√©currents.
Les exemples identifi√©s sont ensuite ajout√©s au dataset d'entra√Ænement pour **enrichir le mod√®le** en se basant sur les conversation concernant la compagnie Air Paradis.
Enfin, **un r√©entra√Ænement et d√©ploiement automatis√©** via le pipeline CI/CD.



## Conclusion

### R√©sultats obtenus
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxx
### Perspectives d'√©volution

xxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxx

### Avantages de l'utilisation des outils IA pour Air Paradis
xxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxx
xxxxxxxxxxx